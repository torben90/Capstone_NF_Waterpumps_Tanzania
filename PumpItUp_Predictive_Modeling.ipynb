{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is the second for my Capstone project. It contains everythin relative to the predective modeling. Starting with setting up pipelines then building different models. The most promising models will be optimized and the results will be visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-the-Notebook\" data-toc-modified-id=\"Setting-up-the-Notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setting up the Notebook</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-of-relevant-modules\" data-toc-modified-id=\"Import-of-relevant-modules-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import of relevant modules</a></span></li><li><span><a href=\"#Macros\" data-toc-modified-id=\"Macros-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Macros</a></span></li><li><span><a href=\"#Utile-Functions\" data-toc-modified-id=\"Utile-Functions-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Utile Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-figure\" data-toc-modified-id=\"Save-figure-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Save figure</a></span></li><li><span><a href=\"#Plotting-Function\" data-toc-modified-id=\"Plotting-Function-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Plotting Function</a></span></li></ul></li></ul></li><li><span><a href=\"#Predictive-Modeling\" data-toc-modified-id=\"Predictive-Modeling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Predictive Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initial-Import-of-the-data\" data-toc-modified-id=\"Initial-Import-of-the-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Initial Import of the data</a></span></li><li><span><a href=\"#Model-Evaluation-function\" data-toc-modified-id=\"Model-Evaluation-function-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Model Evaluation function</a></span></li><li><span><a href=\"#Building-a-preprocessing-pipeline\" data-toc-modified-id=\"Building-a-preprocessing-pipeline-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Building a preprocessing pipeline</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Starting-with-a-DummyClassifier\" data-toc-modified-id=\"Starting-with-a-DummyClassifier-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Starting with a DummyClassifier</a></span></li><li><span><a href=\"#Logistics-Regression\" data-toc-modified-id=\"Logistics-Regression-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Logistics Regression</a></span></li><li><span><a href=\"#Naive-Bayes-Classifier\" data-toc-modified-id=\"Naive-Bayes-Classifier-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Naive Bayes Classifier</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>Random Forest</a></span></li></ul></li><li><span><a href=\"#AdaBoost\" data-toc-modified-id=\"AdaBoost-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>AdaBoost</a></span></li><li><span><a href=\"#Support-Vector-Classifier\" data-toc-modified-id=\"Support-Vector-Classifier-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Support Vector Classifier</a></span></li><li><span><a href=\"#Other-models?\" data-toc-modified-id=\"Other-models?-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Other models?</a></span></li><li><span><a href=\"#Playing-with-learning-curves\" data-toc-modified-id=\"Playing-with-learning-curves-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Playing with learning curves</a></span></li></ul></li><li><span><a href=\"#Appendix\" data-toc-modified-id=\"Appendix-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Appendix</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing-Submission\" data-toc-modified-id=\"Preparing-Submission-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Preparing Submission</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step I will load the relevant modules into the notebook, define some macro settings (Folder etc.) and group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:19:45.986492Z",
     "start_time": "2020-04-29T19:19:44.517958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Torben\\anaconda3\\envs\\nf\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict,GridSearchCV,RandomizedSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix,precision_recall_curve,confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, fbeta_score, roc_auc_score\n",
    "from sklearn.metrics import plot_precision_recall_curve, plot_confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:37:47.752591Z",
     "start_time": "2020-04-29T19:37:47.721542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting some genereral data like folgers and random seed \n",
    "    DATA_FOLDER = './data/'\n",
    "    FIG_FOLDER = './figures/'\n",
    "    MODEL_FOLDER = './models/'\n",
    "    RSEED = 42\n",
    "\n",
    "# Changing some default values for plotting \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['patch.force_edgecolor'] = True\n",
    "    sns.set_style(\"white\")\n",
    "# sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:37:49.018583Z",
     "start_time": "2020-04-29T19:37:49.002962Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utile Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:01:47.352817Z",
     "start_time": "2020-04-29T19:01:47.337197Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(sec_name, fig_name, tight_layout=True,dpi=600):\n",
    "    path = os.path.join(FIG_FOLDER , sec_name + '_'  + fig_name + \".png\")\n",
    "    print(\"Saving figure\", fig_name)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Import of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:37:52.487920Z",
     "start_time": "2020-04-29T19:37:52.316201Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(DATA_FOLDER + 'train_featured_clean.pkl')\n",
    "val = pd.read_pickle(DATA_FOLDER + 'val_featured_clean.pkl')\n",
    "# competition = pd.read_pickle(DATA_FOLDER + 'test_featured_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:07.109051Z",
     "start_time": "2020-04-29T19:40:07.093462Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropped features \n",
    "to_drop = ['scheme_name',\n",
    " 'installer',\n",
    " 'wpt_name',\n",
    " 'subvillage',\n",
    " 'id',\n",
    " 'recorded_by',\n",
    " 'payment',\n",
    " 'quantity_group',\n",
    " 'quality_group',\n",
    " 'waterpoint_type_group',\n",
    " 'extraction_type_group',\n",
    " 'management_group',\n",
    " 'source_class',\n",
    " 'source_type',\n",
    " 'region_code',\n",
    " 'ward']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:38:28.183509Z",
     "start_time": "2020-04-29T19:38:28.167898Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_mod = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:38:28.917879Z",
     "start_time": "2020-04-29T19:38:28.886664Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_eval(m, X_train, X_test, y_train, y_test,name, df=compare_mod,  thres=0.5,fbeta=0.5):\n",
    "    \n",
    "    y_ins_pred= m.predict(X_train)\n",
    "    y_outs_pred= m.predict(X_test)\n",
    "    try:\n",
    "        y_ins_pred_p= m.predict_proba(X_train)[:, 1]\n",
    "        y_outs_pred_p= m.predict_proba(X_test)[:, 1]\n",
    "        if thres!=0.5:\n",
    "\n",
    "            y_ins_pred = [1. if e > thres else 0. for e in y_ins_pred_p]\n",
    "            y_outs_pred = [1. if e > thres else 0. for e in y_outs_pred_p]\n",
    "    except:\n",
    "        y_ins_pred_p= y_ins_pred\n",
    "        y_outs_pred_p= y_ins_pred \n",
    "        \n",
    "    df.at['test  recall', name] = recall_score(y_test, y_outs_pred, average='weighted')\n",
    "    df.at['train recall', name] = recall_score(y_train, y_ins_pred, average='weighted')\n",
    "    \n",
    "    df.at['test  precision', name] = precision_score(y_test, y_outs_pred, average='weighted')\n",
    "    df.at['train precision', name] = precision_score(y_train, y_ins_pred, average='weighted')\n",
    "   \n",
    "    # df.at['test  ROC-AUC', name] = roc_auc_score(y_test, y_outs_pred)\n",
    "    # df.at['train ROC-AUC', name] = roc_auc_score(y_train, y_ins_pred)\n",
    "    \n",
    "    df.at['test  f1', name] = f1_score(y_test, y_outs_pred,average='weighted')\n",
    "    df.at['train f1', name] = f1_score(y_train, y_ins_pred,average='weighted')\n",
    "    \n",
    "    df.at[f'test  fb={fbeta}', name] = fbeta_score(y_test, y_outs_pred, fbeta,average='weighted')\n",
    "    df.at[f'train fb={fbeta}', name] = fbeta_score(y_train, y_ins_pred, fbeta,average='weighted')\n",
    "    \n",
    "    df.at['test  accuracy', name] = accuracy_score(y_test, y_outs_pred)\n",
    "    df.at['train accuracy', name] = accuracy_score(y_train, y_ins_pred)    \n",
    "    \n",
    "    print('--')\n",
    "    print(f'test  recall = {recall_score(y_test, y_outs_pred,average=\"weighted\")}')\n",
    "    print(f'train recall = {recall_score(y_train, y_ins_pred,average=\"weighted\")}')\n",
    "    print('--')\n",
    "    print(f'test  precision = {precision_score(y_test, y_outs_pred,average=\"weighted\")}')\n",
    "    print(f'train precision = {precision_score(y_train, y_ins_pred,average=\"weighted\")}')\n",
    "    print('--')\n",
    "    #print(f'test  ROC-AUC = {roc_auc_score(y_test, y_outs_pred,average=\"weighted\")}')\n",
    "    #print(f'train ROC-AUC = {roc_auc_score(y_train, y_ins_pred,average=\"weighted\")}')\n",
    "    print('--')\n",
    "    print(f'test  accuracy = {accuracy_score(y_test, y_outs_pred)}')\n",
    "    print(f'train accuracy = {accuracy_score(y_train, y_ins_pred)}')\n",
    "    print('--')  \n",
    "\n",
    "    print(classification_report(y_test, y_outs_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:11.688280Z",
     "start_time": "2020-04-29T19:40:11.657066Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the features defined as not neccessary in the previos chapters\n",
    "train.drop(to_drop,1, inplace=True)\n",
    "val.drop(to_drop,1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:16.204970Z",
     "start_time": "2020-04-29T19:40:16.189320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'gps_height',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'num_private',\n",
       " 'population',\n",
       " 'time_in_operation']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = list(train.columns[train.dtypes!=object])\n",
    "numeric_features.remove('permit')\n",
    "numeric_features.remove('public_meeting')\n",
    "numeric_features.remove('district_code')\n",
    "# numeric_features.remove('num_private')\n",
    "# numeric_features.remove('date_recorded')\n",
    "# numeric_features.remove('construction_year')\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:24.035434Z",
     "start_time": "2020-04-29T19:40:24.019820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['funder',\n",
       " 'basin',\n",
       " 'region',\n",
       " 'lga',\n",
       " 'scheme_management',\n",
       " 'extraction_type',\n",
       " 'management',\n",
       " 'payment_type',\n",
       " 'water_quality',\n",
       " 'quantity',\n",
       " 'source',\n",
       " 'waterpoint_type']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_features = list(train.columns[train.dtypes==object])\n",
    "categoric_features.remove('status_group')\n",
    "categoric_features.remove('extraction_type_class')\n",
    "categoric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:23:47.353889Z",
     "start_time": "2020-04-29T09:23:47.322676Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# \n",
    "# class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, dtype):\n",
    "#         self.dtype = dtype\n",
    "# \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "# \n",
    "#     def transform(self, X):\n",
    "#         assert isinstance(X, pd.DataFrame)\n",
    "#         return X.select_dtypes(include=[self.dtype])\n",
    "#     \n",
    "# class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, columns):\n",
    "#         self.columns = columns\n",
    "# \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "# \n",
    "#     def transform(self, X):\n",
    "#         assert isinstance(X, pd.DataFrame)\n",
    "# \n",
    "#         try:\n",
    "#             return X[self.columns]\n",
    "#         except KeyError:\n",
    "#             cols_error = list(set(self.columns) - set(X.columns))\n",
    "#             raise KeyError(\"The DataFrame does not include the columns: %s\" % cols_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:23:47.369541Z",
     "start_time": "2020-04-29T09:23:47.353889Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess_pipeline = make_pipeline(\n",
    "#     ColumnSelector(columns=df_x_encoded.columns),\n",
    "#     FeatureUnion(transformer_list=[\n",
    "#         (\"numeric_features\", make_pipeline(\n",
    "#             TypeSelector('float64'),\n",
    "#             StandardScaler()\n",
    "#         )),\n",
    "#         (\"bool_features\", make_pipeline(\n",
    "#             TypeSelector('int64'),\n",
    "#         )),\n",
    "#         (\"dummy_features\", make_pipeline(\n",
    "#             TypeSelector('uint8'),\n",
    "#         )),\n",
    "#         #(\"categorical_features\", make_pipeline(\n",
    "#         #    TypeSelector(\"category\"),\n",
    "#         #    OneHotEncoder()\n",
    "#         #)),\n",
    "#     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:23:47.400781Z",
     "start_time": "2020-04-29T09:23:47.369541Z"
    }
   },
   "outputs": [],
   "source": [
    "# # checks on the preprocessing pipeline\n",
    "# preprocess_pipeline.fit(df_x_encoded)\n",
    "# X_transformed = preprocess_pipeline.transform(df_x_encoded)    \n",
    "# print(X_transformed.shape)\n",
    "# print(df_x_encoded.shape)\n",
    "# df_y.shape\n",
    "# #df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:35.023007Z",
     "start_time": "2020-04-29T19:40:35.007377Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))]) #,sparse=False\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categoric_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:38.789468Z",
     "start_time": "2020-04-29T19:40:38.758428Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train.status_group\n",
    "y_val = val.status_group\n",
    "X_train = train.drop('status_group',1)\n",
    "X_val = val.drop('status_group',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:40.821025Z",
     "start_time": "2020-04-29T19:40:40.461555Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:42.946241Z",
     "start_time": "2020-04-29T19:40:42.930649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 255)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with a DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:49.509589Z",
     "start_time": "2020-04-29T19:40:49.462718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430976430976431"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:51.775718Z",
     "start_time": "2020-04-29T19:40:50.166085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "test  recall = 0.5430976430976431\n",
      "train recall = 0.5430765993265994\n",
      "--\n",
      "test  precision = 0.2949550499382149\n",
      "train precision = 0.2949321927361437\n",
      "--\n",
      "--\n",
      "test  accuracy = 0.5430976430976431\n",
      "train accuracy = 0.5430765993265994\n",
      "--\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.54      1.00      0.70      6452\n",
      "functional needs repair       0.00      0.00      0.00       863\n",
      "         non functional       0.00      0.00      0.00      4565\n",
      "\n",
      "               accuracy                           0.54     11880\n",
      "              macro avg       0.18      0.33      0.23     11880\n",
      "           weighted avg       0.29      0.54      0.38     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_eval(dummy,X_train,X_val,y_train,y_val,'Dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:40:56.026244Z",
     "start_time": "2020-04-29T19:40:56.010622Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      \n",
    "                      ('classifier', LogisticRegressionCV(cv=5,random_state=RSEED))\n",
    "                       \n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:41:56.761843Z",
     "start_time": "2020-04-29T19:40:56.854443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean...\n",
       "                                                   'water_quality', 'quantity',\n",
       "                                                   'source',\n",
       "                                                   'waterpoint_type'])],\n",
       "                                   verbose=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegressionCV(Cs=10, class_weight=None, cv=5,\n",
       "                                      dual=False, fit_intercept=True,\n",
       "                                      intercept_scaling=1.0, l1_ratios=None,\n",
       "                                      max_iter=100, multi_class='auto',\n",
       "                                      n_jobs=None, penalty='l2',\n",
       "                                      random_state=42, refit=True, scoring=None,\n",
       "                                      solver='lbfgs', tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:41:56.839949Z",
     "start_time": "2020-04-29T19:41:56.761843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7490740740740741"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:41:57.105512Z",
     "start_time": "2020-04-29T19:41:56.839949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7536616161616162"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:24:53.815703Z",
     "start_time": "2020-04-29T09:24:53.784462Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_train_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:42:14.561326Z",
     "start_time": "2020-04-29T19:42:11.936240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "test  recall = 0.7490740740740741\n",
      "train recall = 0.7536616161616162\n",
      "--\n",
      "test  precision = 0.7367413635715783\n",
      "train precision = 0.7481479651709771\n",
      "--\n",
      "--\n",
      "test  accuracy = 0.7490740740740741\n",
      "train accuracy = 0.7536616161616162\n",
      "--\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.74      0.90      0.81      6452\n",
      "functional needs repair       0.46      0.10      0.16       863\n",
      "         non functional       0.79      0.67      0.72      4565\n",
      "\n",
      "               accuracy                           0.75     11880\n",
      "              macro avg       0.66      0.55      0.56     11880\n",
      "           weighted avg       0.74      0.75      0.73     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_eval(reg,X_train,X_val,y_train,y_val,'LogReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:29:49.974833Z",
     "start_time": "2020-04-29T09:29:49.959213Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:42:19.187326Z",
     "start_time": "2020-04-29T19:42:19.171735Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "logistics = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:42:19.718755Z",
     "start_time": "2020-04-29T19:42:19.703105Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_log = RandomizedSearchCV(logistics, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:45:21.257235Z",
     "start_time": "2020-04-29T19:42:20.625274Z"
    }
   },
   "outputs": [],
   "source": [
    "best_log = clf_log.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:45:21.272858Z",
     "start_time": "2020-04-29T19:45:21.257235Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = [LogisticRegression(solver=\"lbfgs\")\n",
    "       , KNeighborsClassifier(n_neighbors=5)\n",
    "       # , SVC(C=1, kernel=\"rbf\", gamma='scale')\n",
    "       , RandomForestClassifier(n_estimators=1000, criterion=\"gini\",min_samples_split=10)\n",
    "       , AdaBoostClassifier()\n",
    "       , XGBClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:32:44.402451Z",
     "start_time": "2020-04-29T09:32:44.386830Z"
    }
   },
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for model in clf:\n",
    "#     model_name = model.__class__.__name__\n",
    "#     results[model_name] = {}\n",
    "#     scores = model_evaluation(X_train_transformed, y_train, model)\n",
    "#     results[model_name] = scores        \n",
    "# #print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.067210Z",
     "start_time": "2020-04-29T09:33:41.051585Z"
    }
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not work with sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.082823Z",
     "start_time": "2020-04-29T09:33:41.067210Z"
    }
   },
   "outputs": [],
   "source": [
    "# randf_ = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.098442Z",
     "start_time": "2020-04-29T09:33:41.082823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:52:48.532049Z",
     "start_time": "2020-04-29T09:52:48.516428Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf_random = RandomizedSearchCV(estimator = randf_\n",
    "#                                , param_distributions = random_grid\n",
    "#                                , n_iter = 100\n",
    "#                                , cv = 3\n",
    "#                                , verbose=2\n",
    "#                                , random_state=42\n",
    "#                                , n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# # clf_random.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.129685Z",
     "start_time": "2020-04-29T09:33:41.110Z"
    }
   },
   "outputs": [],
   "source": [
    "# joblib.dump(clf_random, \"rfc_randomcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:46:36.849993Z",
     "start_time": "2020-04-29T19:46:27.390189Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_random = joblib.load(MODEL_FOLDER + \"rfc_randomcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:46:44.648265Z",
     "start_time": "2020-04-29T19:46:44.632644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.804\n",
      "Best model: {'n_estimators': 1800, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print('Best score:', round(clf_random.best_score_,3))\n",
    "print('Best model:', clf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:46:47.242171Z",
     "start_time": "2020-04-29T19:46:47.226800Z"
    }
   },
   "outputs": [],
   "source": [
    "best_rfc = clf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:46:48.273559Z",
     "start_time": "2020-04-29T19:46:48.242575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11880, 255)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:46:49.070525Z",
     "start_time": "2020-04-29T19:46:49.054958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 255)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:47:57.227006Z",
     "start_time": "2020-04-29T19:47:57.211610Z"
    }
   },
   "outputs": [],
   "source": [
    "# random_pred = clf_random.predict(X_val_transformed)\n",
    "# print('Validation score: ',round(accuracy_score(y_val,random_pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:48:00.774559Z",
     "start_time": "2020-04-29T19:48:00.758963Z"
    }
   },
   "outputs": [],
   "source": [
    "model_eval(clf_random,X_train_transformed,X_val_transformed,y_train,y_val,'RFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:45:21.304100Z",
     "start_time": "2020-04-29T19:42:58.221Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_mod.T*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.239034Z",
     "start_time": "2020-04-29T09:33:41.183Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_log=Pipeline([('pre',preprocessor), \n",
    "              ('model',AdaBoostClassifier(base_estimator=LogisticRegression(C=0.03),\n",
    "                                      random_state=RSEED))])\n",
    "ada_log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.239034Z",
     "start_time": "2020-04-29T09:33:41.192Z"
    }
   },
   "outputs": [],
   "source": [
    "model_eval(ada_log,X_train,X_val,y_train,y_val,'AdaBoost Log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.239034Z",
     "start_time": "2020-04-29T09:33:41.200Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_rfc=Pipeline([('pre',preprocessor), \n",
    "              ('model',AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=1),\n",
    "                                      random_state=RSEED))])\n",
    "ada_rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.239034Z",
     "start_time": "2020-04-29T09:33:41.209Z"
    }
   },
   "outputs": [],
   "source": [
    "model_eval(ada_rfc,X_train,X_val,y_train,y_val,'AdaBoost RFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.239034Z",
     "start_time": "2020-04-29T09:33:41.222Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_DCT=Pipeline([('pre',preprocessor), \n",
    "              ('model',AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                                      random_state=RSEED))])\n",
    "ada_DCT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:33:41.364343Z",
     "start_time": "2020-04-29T09:33:41.333103Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_mod.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:51:06.144042Z",
     "start_time": "2020-04-29T09:51:00.232Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(RandomForestClassifier(), \n",
    "                                                        X_train_transformed, \n",
    "                                                        y_train,\n",
    "                                                        # Number of folds in cross-validation\n",
    "                                                        cv=10,\n",
    "                                                        # Evaluation metric\n",
    "                                                        scoring='accuracy',\n",
    "                                                        # Use all computer cores\n",
    "                                                        n_jobs=-1, \n",
    "                                                        # 50 different sizes of the training set\n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:51:06.144042Z",
     "start_time": "2020-04-29T09:33:41.302Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import scikitplot as skplt\n",
    "# rf = RandomForestClassifier()\n",
    "# skplt.estimators.plot_learning_curve(rf, X_train_transformed,y_train)\n",
    "# \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:51:06.144042Z",
     "start_time": "2020-04-29T09:33:41.325Z"
    }
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'id':X_test.id,'status_group':submission_predict.astype(int)})\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:51:06.144042Z",
     "start_time": "2020-04-29T09:33:41.333Z"
    }
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('private/submission.csv',index=False)\n",
    "# submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
